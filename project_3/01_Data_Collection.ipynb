{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11cf40d6",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f4f10",
   "metadata": {},
   "source": [
    "**Problem Statement:** When performing maintenance, an engineer accidentally deleted multiple posts from r/nottheonion and r/theonion. Unfortunately, the engineer was only able to recover the titles of the lost posts. \n",
    "\n",
    "We were therefore tasked to build a classification model which would train on posts submitted before 01 Jan 2022 to classify the recovered posts back to their respective subreddits, r/nottheonion and r/theonion, based solely on the post titles.\n",
    "\n",
    "This model would also be used as a proof of concept for the development of an automated moderator which would automatically delete posts that do not belong to the subreddit that they are posted to. There has been an increase in bots spamming subreddits with irrelevant posts. \n",
    "\n",
    "Moderators have been spending a substantial amount of their time reviewing user reports and deleting spam posts from the subreddit. Having automated moderators police the subreddit for spam posts would free up time for human moderators, who are volunteers, to do things that they want to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f917d7",
   "metadata": {},
   "source": [
    "\n",
    "**Web Data Scraping Using Pushshift API**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d244773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import for API \n",
    "from psaw import PushshiftAPI\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a2934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup parameters\n",
    "def data_scrape(subreddit):\n",
    "    \n",
    "    # Instantiate \n",
    "    api = PushshiftAPI()\n",
    "\n",
    "    #list for data scraped \n",
    "    scrape_l = list(api.search_submissions(subreddit=subreddit,\n",
    "                                before = 1640995200,\n",
    "                                filter=['title', 'subreddit', 'num_comments', 'author', 'subreddit_subscribers', 'score', 'domain', 'created_utc'],\n",
    "                                limit=2500))\n",
    "\n",
    "    #filter to only show Subreddit titles and its category \n",
    "    clean_scrape_1 = []\n",
    "    for i in range(len(scrape_l)):\n",
    "        scrape_dict = {}\n",
    "        scrape_dict['subreddit'] = scrape_l[i][5]\n",
    "        scrape_dict['author'] = scrape_l[i][0]\n",
    "        scrape_dict['domain'] = scrape_l[i][2]\n",
    "        scrape_dict['title'] = scrape_l[i][7]\n",
    "        scrape_dict['num_comments'] = scrape_l[i][3]\n",
    "        scrape_dict['score'] = scrape_l[i][4]\n",
    "        scrape_dict['timestamp'] = scrape_l[i][1]\n",
    "        clean_scrape_1.append(scrape_dict)\n",
    "\n",
    "    # num of subscribers\n",
    "    print(subreddit, 'subscribers:',scrape_l[1][6])\n",
    "    \n",
    "    # Return list \n",
    "    return clean_scrape_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee074b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nottheonion subscribers: 20438921\n"
     ]
    }
   ],
   "source": [
    "# create DataFrame\n",
    "not_onion = pd.DataFrame(data_scrape('nottheonion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a85d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv\n",
    "not_onion.to_csv('./not_onion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed82eb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_onion shape: (2497, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Taco_duck68</td>\n",
       "      <td>wral.com</td>\n",
       "      <td>Man attempts to pay for car with rap, steals p...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1640995192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>BlackNingaa</td>\n",
       "      <td>bloodyelbow.com</td>\n",
       "      <td>Former UFC fighter reveals past as sex worker ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1640994707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Lopsided_File_1642</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>Log into Facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1640991506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>SkinnyWhiteGirl19</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>McDonald’s blocked from building drive-through...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1640990429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>kids-cake-and-crazy</td>\n",
       "      <td>kjrh.com</td>\n",
       "      <td>Legendary actress Betty White dies at 99 on Ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1640989181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author               domain  \\\n",
       "0  nottheonion          Taco_duck68             wral.com   \n",
       "1  nottheonion          BlackNingaa      bloodyelbow.com   \n",
       "2  nottheonion   Lopsided_File_1642         facebook.com   \n",
       "3  nottheonion    SkinnyWhiteGirl19  theartnewspaper.com   \n",
       "4  nottheonion  kids-cake-and-crazy             kjrh.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  Man attempts to pay for car with rap, steals p...             0      1   \n",
       "1  Former UFC fighter reveals past as sex worker ...             1      1   \n",
       "2                                  Log into Facebook             1      1   \n",
       "3  McDonald’s blocked from building drive-through...             0      1   \n",
       "4  Legendary actress Betty White dies at 99 on Ne...             0      1   \n",
       "\n",
       "    timestamp  \n",
       "0  1640995192  \n",
       "1  1640994707  \n",
       "2  1640991506  \n",
       "3  1640990429  \n",
       "4  1640989181  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "print(f'not_onion shape: {not_onion.shape}')\n",
    "\n",
    "# check head\n",
    "not_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9790c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheOnion subscribers: 165298\n"
     ]
    }
   ],
   "source": [
    "# create onion DataFrame\n",
    "onion = pd.DataFrame(data_scrape('TheOnion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a267c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv\n",
    "onion.to_csv('./onion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10cbdf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onion shape: (2497, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>mothershipq</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>Surgeon Kind Of Pissed Patient Seeing Her Defo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1640973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>-ImYourHuckleberry-</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>McDonald’s blocked from building drive-through...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1640971771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>Gwyneth Paltrow Touts New Diamond-Encrusted Tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1640955671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>Artist Crafting Music Box Hopes It Delights At...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1640955669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>Homeowner Trying To Smoke Out Snakes Accidenta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1640955668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author               domain  \\\n",
       "0  TheOnion          mothershipq         theonion.com   \n",
       "1  TheOnion  -ImYourHuckleberry-  theartnewspaper.com   \n",
       "2  TheOnion                dwaxe         theonion.com   \n",
       "3  TheOnion                dwaxe         theonion.com   \n",
       "4  TheOnion                dwaxe         theonion.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  Surgeon Kind Of Pissed Patient Seeing Her Defo...             0      1   \n",
       "1  McDonald’s blocked from building drive-through...             1      1   \n",
       "2  Gwyneth Paltrow Touts New Diamond-Encrusted Tr...             0      1   \n",
       "3  Artist Crafting Music Box Hopes It Delights At...             0      1   \n",
       "4  Homeowner Trying To Smoke Out Snakes Accidenta...             0      1   \n",
       "\n",
       "    timestamp  \n",
       "0  1640973300  \n",
       "1  1640971771  \n",
       "2  1640955671  \n",
       "3  1640955669  \n",
       "4  1640955668  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "print(f'onion shape: {onion.shape}')\n",
    "\n",
    "# check head\n",
    "onion.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
